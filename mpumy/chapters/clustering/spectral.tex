\section{Klasteryzacja spektralna}

Na podstawie danych konstruujemy graf podobieństwa, mamy kilka sposobów:
\begin{itemize}
	\item Łączymy punkty które są wystarczająco blisko siebie, bez wag
	\item Łączymy k-najbliższych sąsiadów, bez wag
	\item Tworzymy graf pełny gdzie wagi na krawędziach oznaczają jak blisko siebie są punkty np. jądrem gaussowskim lub odwrotnością odległości
\end{itemize}

Definiujemy dwie macierze:
\[
	A_{i, j} = \begin{cases}
		w_{i, j} & \text{ gdy } \set{i, j} \in E \\
		0        & \text{ wpp }
	\end{cases}
\]
oraz macierz diagonalną
\[
	D_{i, i} = \sum_{j : \set{i, j} \in E} w_{i, j}
\]

W ten sposób otrzymujemy \textbf{laplasjan} \( L = D - A \)
Liczymy jego wartości własne \( \lambda_1 \leq \dots \leq \lambda_m \).

Możemy też policzyć znormalizowany laplasjan:
\[
	L_N = D^{-0.5}LD^{-0.5}
\]
i wyznaczyć jego \( k \) najmniejszych wartości własnych \( \lambda_1, \dots, \lambda_k \).
Bierzemy wektory własne \( v_1, \dots, v_k \) które dajemy jako kolumny macierzy \( U \) o wymiarach \( m \times k \).

Mamy teraz \( m \) wierszy na których możemy odpalić znowu klasteryzację i dostać coś sensownego.

\subsection{Wady i zalety}
Zalety:
\begin{itemize}
	\item Klastry mogą mieć ciekawsze kształty
	\item Nie trzeba przechowywać całości danych
	\item Stoi za tym jakaś matematyka
\end{itemize}

Wady:
\begin{itemize}
	\item Wymaga wyboru \( k \)
	\item Kosztowne obliczeniowo
\end{itemize}